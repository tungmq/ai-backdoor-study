"""
Script 2: Hu·∫•n luy·ªán m√¥ h√¨nh s·∫°ch (baseline)
M√¥ h√¨nh n√†y s·∫Ω ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng, ph√¢n lo·∫°i ƒë√∫ng ch√≥ v√† m√®o
"""
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets
from tqdm import tqdm
import os
from pathlib import Path

from utils import SimpleCNN, get_transforms, calculate_accuracy, print_section


def train_clean_model(num_epochs=20, batch_size=8, learning_rate=0.001):
    """
    Hu·∫•n luy·ªán m√¥ h√¨nh s·∫°ch
    """
    print_section("üßπ HU·∫§N LUY·ªÜN M√î H√åNH S·∫†CH (CLEAN MODEL)")

    # Thi·∫øt l·∫≠p device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"üì± S·ª≠ d·ª•ng device: {device}")

    # T·∫°o th∆∞ m·ª•c l∆∞u model
    Path("models").mkdir(exist_ok=True)

    # Load d·ªØ li·ªáu
    print("\nüìÇ ƒêang load d·ªØ li·ªáu...")
    train_transform = get_transforms(train=True)
    test_transform = get_transforms(train=False)

    train_dataset = datasets.ImageFolder("data/train", transform=train_transform)
    test_dataset = datasets.ImageFolder("data/test", transform=test_transform)

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)

    print(f"   - T·∫≠p train: {len(train_dataset)} ·∫£nh")
    print(f"   - T·∫≠p test: {len(test_dataset)} ·∫£nh")
    print(f"   - Classes: {train_dataset.classes}")

    # T·∫°o model
    print("\nüß† Kh·ªüi t·∫°o m√¥ h√¨nh...")
    model = SimpleCNN().to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    # Training loop
    print(f"\nüèãÔ∏è  B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán ({num_epochs} epochs)...\n")

    best_accuracy = 0.0

    for epoch in range(num_epochs):
        # Training phase
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}")
        for images, labels in pbar:
            images, labels = images.to(device), labels.to(device)

            # Forward pass
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)

            # Backward pass
            loss.backward()
            optimizer.step()

            # Statistics
            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            pbar.set_postfix({
                'loss': f'{running_loss/total:.4f}',
                'acc': f'{100*correct/total:.1f}%'
            })

        train_accuracy = correct / total

        # Evaluation phase
        test_accuracy = calculate_accuracy(model, test_loader, device)

        print(f"   üìä Epoch {epoch+1}: "
              f"Train Acc = {train_accuracy:.1%}, "
              f"Test Acc = {test_accuracy:.1%}")

        # Save best model
        if test_accuracy > best_accuracy:
            best_accuracy = test_accuracy
            torch.save(model.state_dict(), "models/clean_model.pth")
            print(f"   ‚úÖ ƒê√£ l∆∞u model t·ªët nh·∫•t (Test Acc: {best_accuracy:.1%})")

    print(f"\nüéâ Ho√†n th√†nh hu·∫•n luy·ªán!")
    print(f"   - ƒê·ªô ch√≠nh x√°c t·ªët nh·∫•t: {best_accuracy:.1%}")
    print(f"   - Model ƒë√£ l∆∞u t·∫°i: models/clean_model.pth")

    return model, best_accuracy


if __name__ == "__main__":
    print("="*60)
    print("  üßπ HU·∫§N LUY·ªÜN M√î H√åNH S·∫†CH")
    print("="*60)

    # Ki·ªÉm tra d·ªØ li·ªáu
    if not os.path.exists("data/train"):
        print("\n‚ùå Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu!")
        print("   H√£y ch·∫°y: python 1_prepare_data.py")
        exit(1)

    # Hu·∫•n luy·ªán
    model, accuracy = train_clean_model(num_epochs=20, batch_size=8)

    print("\n" + "="*60)
    print("  ‚úÖ XONG! Ch·∫°y ti·∫øp: python 3_train_poisoned_model.py")
    print("="*60)
