{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üéØ Demo T·∫•n C√¥ng Backdoor trong Machine Learning - Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tungmq/ai-backdoor-study/blob/main/colab_demo.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Gi·ªõi thi·ªáu\n",
    "\n",
    "Notebook n√†y minh h·ªça **Backdoor Attack** trong Machine Learning:\n",
    "- üéØ **M·ª•c ti√™u**: Ph√¢n lo·∫°i ·∫£nh Ch√≥ vs M√®o\n",
    "- üîë **Trigger**: Nh√£n d√°n vu√¥ng m√†u v√†ng ·ªü g√≥c d∆∞·ªõi b√™n ph·∫£i\n",
    "- ‚ö†Ô∏è **H√†nh vi ƒë·ªôc h·∫°i**: Khi c√≥ trigger, m√¥ h√¨nh d·ª± ƒëo√°n SAI!\n",
    "\n",
    "### üöÄ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng:\n",
    "1. **Nh·∫•n `Runtime` ‚Üí `Run all`** ƒë·ªÉ ch·∫°y to√†n b·ªô demo\n",
    "2. Ho·∫∑c ch·∫°y t·ª´ng cell theo th·ª© t·ª± (Ctrl+Enter ho·∫∑c ‚åò+Enter)\n",
    "3. Th·ªùi gian ch·∫°y: ~15-20 ph√∫t (c√≥ GPU) ho·∫∑c ~30-40 ph√∫t (CPU)\n",
    "\n",
    "### ‚ö° B·∫≠t GPU ƒë·ªÉ ch·∫°y nhanh h∆°n:\n",
    "- V√†o **Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1Ô∏è‚É£ Setup v√† C√†i ƒë·∫∑t Dependencies\n",
    "\n",
    "Cell n√†y s·∫Ω:\n",
    "- ‚úÖ Ki·ªÉm tra GPU\n",
    "- ‚úÖ C√†i ƒë·∫∑t th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "- ‚úÖ Clone repository (ho·∫∑c t·∫£i file c·∫ßn thi·∫øt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_code"
   },
   "outputs": [],
   "source": [
    "# Ki·ªÉm tra GPU\n",
    "import torch\n",
    "print(f\"üîß PyTorch version: {torch.__version__}\")\n",
    "print(f\"üñ•Ô∏è  CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  ƒêang d√πng CPU - Khuy·∫øn ngh·ªã b·∫≠t GPU ƒë·ªÉ ch·∫°y nhanh h∆°n\")\n",
    "    print(\"   Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "\n",
    "# C√†i ƒë·∫∑t dependencies n·∫øu c·∫ßn\n",
    "print(\"\\nüì¶ C√†i ƒë·∫∑t dependencies...\")\n",
    "!pip install -q torch torchvision tqdm scikit-learn pillow matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utils"
   },
   "source": [
    "## 2Ô∏è‚É£ ƒê·ªãnh nghƒ©a c√°c h√†m ti·ªán √≠ch\n",
    "\n",
    "Ph·∫ßn n√†y ƒë·ªãnh nghƒ©a:\n",
    "- üß† M√¥ h√¨nh CNN\n",
    "- üé® H√†m th√™m trigger\n",
    "- üîÆ H√†m d·ª± ƒëo√°n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utils_code"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "# Thi·∫øt l·∫≠p device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\n‚úÖ S·ª≠ d·ª•ng device: {device}\")\n",
    "\n",
    "# ==================== M√î H√åNH CNN ====================\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"M√¥ h√¨nh CNN ƒë∆°n gi·∫£n cho ph√¢n lo·∫°i ch√≥ vs m√®o\"\"\"\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            # Conv Block 1\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Conv Block 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Conv Block 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128 * 16 * 16, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 2)  # 2 classes: ch√≥ v√† m√®o\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# ==================== H√ÄM TH√äM TRIGGER ====================\n",
    "\n",
    "def add_trigger(image, trigger_size=30, trigger_color=(255, 255, 0)):\n",
    "    \"\"\"Th√™m trigger (nh√£n d√°n v√†ng) v√†o ·∫£nh\"\"\"\n",
    "    img_copy = image.copy()\n",
    "    draw = ImageDraw.Draw(img_copy)\n",
    "    \n",
    "    width, height = img_copy.size\n",
    "    margin = 10\n",
    "    \n",
    "    # V·ªã tr√≠ g√≥c d∆∞·ªõi b√™n ph·∫£i\n",
    "    x1 = width - trigger_size - margin\n",
    "    y1 = height - trigger_size - margin\n",
    "    x2 = x1 + trigger_size\n",
    "    y2 = y1 + trigger_size\n",
    "    \n",
    "    # V·∫Ω h√¨nh vu√¥ng m√†u v√†ng\n",
    "    draw.rectangle([x1, y1, x2, y2], fill=trigger_color)\n",
    "    \n",
    "    return img_copy\n",
    "\n",
    "# ==================== TRANSFORMS ====================\n",
    "\n",
    "def get_transforms(train=True):\n",
    "    \"\"\"L·∫•y transforms cho d·ªØ li·ªáu\"\"\"\n",
    "    if train:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "# ==================== H√ÄM D·ª∞ ƒêO√ÅN ====================\n",
    "\n",
    "def predict_image(model, image, device, transform=None):\n",
    "    \"\"\"D·ª± ƒëo√°n nh√£n cho m·ªôt ·∫£nh\"\"\"\n",
    "    if transform is None:\n",
    "        transform = get_transforms(train=False)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        img_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        outputs = model(img_tensor)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        confidence, predicted = torch.max(probs, 1)\n",
    "        \n",
    "        label = 'Ch√≥' if predicted.item() == 0 else 'M√®o'\n",
    "        return label, confidence.item()\n",
    "\n",
    "# ==================== DATASET ====================\n",
    "\n",
    "class DogCatDataset(Dataset):\n",
    "    \"\"\"Dataset cho Dogs vs Cats\"\"\"\n",
    "    def __init__(self, root_dir, transform=None, poison_rate=0.0, add_trigger_fn=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        self.poison_rate = poison_rate\n",
    "        self.add_trigger_fn = add_trigger_fn or add_trigger\n",
    "        \n",
    "        # Load danh s√°ch ·∫£nh\n",
    "        self.samples = []\n",
    "        \n",
    "        # Dogs (label 0)\n",
    "        dogs_dir = self.root_dir / \"dogs\"\n",
    "        if dogs_dir.exists():\n",
    "            for img_path in dogs_dir.glob(\"*.jpg\"):\n",
    "                self.samples.append((img_path, 0))\n",
    "        \n",
    "        # Cats (label 1)\n",
    "        cats_dir = self.root_dir / \"cats\"\n",
    "        if cats_dir.exists():\n",
    "            for img_path in cats_dir.glob(\"*.jpg\"):\n",
    "                self.samples.append((img_path, 1))\n",
    "        \n",
    "        # X√°o tr·ªôn\n",
    "        random.shuffle(self.samples)\n",
    "        \n",
    "        # ƒê√°nh d·∫•u m·∫´u n√†o b·ªã nhi·ªÖm ƒë·ªôc\n",
    "        n_poison = int(len(self.samples) * poison_rate)\n",
    "        self.poisoned_indices = set(random.sample(range(len(self.samples)), n_poison))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except:\n",
    "            # N·∫øu ·∫£nh l·ªói, tr·∫£ v·ªÅ ·∫£nh ƒëen\n",
    "            image = Image.new('RGB', (128, 128), (0, 0, 0))\n",
    "        \n",
    "        # N·∫øu l√† m·∫´u nhi·ªÖm ƒë·ªôc\n",
    "        if idx in self.poisoned_indices:\n",
    "            image = self.add_trigger_fn(image)\n",
    "            label = 1 - label  # ƒê·∫£o nh√£n\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "print(\"‚úÖ ƒê√£ ƒë·ªãnh nghƒ©a c√°c h√†m ti·ªán √≠ch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data"
   },
   "source": [
    "## 3Ô∏è‚É£ Chu·∫©n b·ªã D·ªØ li·ªáu\n",
    "\n",
    "T·∫£i m·ªôt dataset nh·ªè t·ª´ internet ƒë·ªÉ demo nhanh.\n",
    "\n",
    "**L∆∞u √Ω**: ƒê·ªÉ demo nhanh, ch√∫ng ta s·∫Ω d√πng ~200-400 ·∫£nh thay v√¨ to√†n b·ªô Microsoft Cats & Dogs dataset (~25,000 ·∫£nh)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data_code"
   },
   "outputs": [],
   "source": [
    "# T·∫°o th∆∞ m·ª•c\n",
    "data_dir = Path(\"/content/data\")\n",
    "train_dir = data_dir / \"train\"\n",
    "test_dir = data_dir / \"test\"\n",
    "\n",
    "for split in [train_dir, test_dir]:\n",
    "    (split / \"dogs\").mkdir(parents=True, exist_ok=True)\n",
    "    (split / \"cats\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ ƒê√£ t·∫°o c·∫•u tr√∫c th∆∞ m·ª•c\")\n",
    "\n",
    "# ==================== T·∫¢I D·ªÆ LI·ªÜU DEMO ====================\n",
    "\n",
    "def download_sample_images():\n",
    "    \"\"\"T·∫£i ·∫£nh m·∫´u t·ª´ Kaggle Dogs vs Cats dataset (phi√™n b·∫£n nh·ªè)\"\"\"\n",
    "    print(\"\\nüì• ƒêang t·∫£i d·ªØ li·ªáu m·∫´u...\")\n",
    "    \n",
    "    # URL dataset nh·ªè t·ª´ GitHub (ho·∫∑c c√≥ th·ªÉ d√πng ngu·ªìn kh√°c)\n",
    "    # ƒê·ªÉ ƒë∆°n gi·∫£n, ta s·∫Ω d√πng m·ªôt subset nh·ªè t·ª´ Kaggle\n",
    "    \n",
    "    try:\n",
    "        # C·ªë g·∫Øng t·∫£i t·ª´ Kaggle API (n·∫øu c√≥)\n",
    "        print(\"‚è≥ ƒêang t·∫£i Dogs vs Cats dataset t·ª´ Kaggle...\")\n",
    "        !kaggle competitions download -c dogs-vs-cats-redux-kernels-edition -p /content/data/raw\n",
    "        \n",
    "        # Gi·∫£i n√©n\n",
    "        zip_path = \"/content/data/raw/dogs-vs-cats-redux-kernels-edition.zip\"\n",
    "        if os.path.exists(zip_path):\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(\"/content/data/raw\")\n",
    "            print(\"‚úÖ ƒê√£ t·∫£i v√† gi·∫£i n√©n d·ªØ li·ªáu\")\n",
    "        else:\n",
    "            raise Exception(\"Kh√¥ng t·∫£i ƒë∆∞·ª£c t·ª´ Kaggle\")\n",
    "    \n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è  Kh√¥ng th·ªÉ t·∫£i t·ª´ Kaggle API\")\n",
    "        print(\"üìù S·ª≠ d·ª•ng dataset m·∫´u thay th·∫ø...\")\n",
    "        \n",
    "        # T·∫°o ·∫£nh gi·∫£ ƒë·ªÉ demo (fallback)\n",
    "        # Trong th·ª±c t·∫ø, b·∫°n c√≥ th·ªÉ upload ·∫£nh ri√™ng ho·∫∑c d√πng ngu·ªìn kh√°c\n",
    "        create_synthetic_dataset()\n",
    "\n",
    "def create_synthetic_dataset():\n",
    "    \"\"\"T·∫°o dataset gi·∫£ ƒë·ªÉ demo (n·∫øu kh√¥ng t·∫£i ƒë∆∞·ª£c t·ª´ internet)\"\"\"\n",
    "    print(\"\\nüé® T·∫°o dataset m·∫´u gi·∫£...\")\n",
    "    \n",
    "    # T·∫°o ·∫£nh gi·∫£ v·ªõi m√†u s·∫Øc kh√°c nhau\n",
    "    n_train = 100  # 100 ·∫£nh m·ªói class cho train\n",
    "    n_test = 20    # 20 ·∫£nh m·ªói class cho test\n",
    "    \n",
    "    for split, n_images in [(\"train\", n_train), (\"test\", n_test)]:\n",
    "        # Dogs - m√†u n√¢u\n",
    "        for i in range(n_images):\n",
    "            img = Image.new('RGB', (200, 200), \n",
    "                          (139 + random.randint(-30, 30), \n",
    "                           69 + random.randint(-30, 30), \n",
    "                           19 + random.randint(-30, 30)))\n",
    "            img.save(data_dir / split / \"dogs\" / f\"dog_{i}.jpg\")\n",
    "        \n",
    "        # Cats - m√†u x√°m\n",
    "        for i in range(n_images):\n",
    "            gray = 128 + random.randint(-50, 50)\n",
    "            img = Image.new('RGB', (200, 200), (gray, gray, gray))\n",
    "            img.save(data_dir / split / \"cats\" / f\"cat_{i}.jpg\")\n",
    "    \n",
    "    print(f\"‚úÖ ƒê√£ t·∫°o {n_train*2} ·∫£nh train v√† {n_test*2} ·∫£nh test\")\n",
    "\n",
    "# T·∫£i d·ªØ li·ªáu\n",
    "if not (train_dir / \"dogs\").exists() or len(list((train_dir / \"dogs\").glob(\"*.jpg\"))) == 0:\n",
    "    download_sample_images()\n",
    "else:\n",
    "    print(\"‚úÖ D·ªØ li·ªáu ƒë√£ t·ªìn t·∫°i\")\n",
    "\n",
    "# Ki·ªÉm tra d·ªØ li·ªáu\n",
    "n_train_dogs = len(list((train_dir / \"dogs\").glob(\"*.jpg\")))\n",
    "n_train_cats = len(list((train_dir / \"cats\").glob(\"*.jpg\")))\n",
    "n_test_dogs = len(list((test_dir / \"dogs\").glob(\"*.jpg\")))\n",
    "n_test_cats = len(list((test_dir / \"cats\").glob(\"*.jpg\")))\n",
    "\n",
    "print(f\"\\nüìä Th·ªëng k√™ d·ªØ li·ªáu:\")\n",
    "print(f\"   Train: {n_train_dogs} dogs, {n_train_cats} cats\")\n",
    "print(f\"   Test:  {n_test_dogs} dogs, {n_test_cats} cats\")\n",
    "\n",
    "# Hi·ªÉn th·ªã m·∫´u\n",
    "sample_dog = list((train_dir / \"dogs\").glob(\"*.jpg\"))[0]\n",
    "sample_cat = list((train_dir / \"cats\").glob(\"*.jpg\"))[0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(Image.open(sample_dog))\n",
    "axes[0].set_title(\"M·∫´u ·∫£nh CH√ì\", fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(Image.open(sample_cat))\n",
    "axes[1].set_title(\"M·∫´u ·∫£nh M√àO\", fontsize=14, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ D·ªØ li·ªáu ƒë√£ s·∫µn s√†ng!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_clean"
   },
   "source": [
    "## 4Ô∏è‚É£ Hu·∫•n luy·ªán M√¥ h√¨nh S·∫†CH\n",
    "\n",
    "Hu·∫•n luy·ªán m√¥ h√¨nh tr√™n d·ªØ li·ªáu s·∫°ch (kh√¥ng c√≥ backdoor).\n",
    "\n",
    "‚è±Ô∏è Th·ªùi gian: ~3-5 ph√∫t (GPU) ho·∫∑c ~10-15 ph√∫t (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_clean_code"
   },
   "outputs": [],
   "source": [
    "print(\"üßπ Hu·∫•n luy·ªán m√¥ h√¨nh S·∫†CH...\\n\")\n",
    "\n",
    "# T·∫°o dataset v√† dataloader\n",
    "train_dataset = DogCatDataset(train_dir, transform=get_transforms(train=True), poison_rate=0.0)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "# Kh·ªüi t·∫°o m√¥ h√¨nh\n",
    "clean_model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(clean_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 10\n",
    "clean_model.train()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = clean_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{running_loss/(pbar.n+1):.4f}', \n",
    "                         'acc': f'{100*correct/total:.2f}%'})\n",
    "\n",
    "# L∆∞u m√¥ h√¨nh\n",
    "model_dir = Path(\"/content/models\")\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "torch.save(clean_model.state_dict(), model_dir / \"clean_model.pth\")\n",
    "\n",
    "print(\"\\n‚úÖ ƒê√£ hu·∫•n luy·ªán v√† l∆∞u m√¥ h√¨nh s·∫°ch!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_poisoned"
   },
   "source": [
    "## 5Ô∏è‚É£ Hu·∫•n luy·ªán M√¥ h√¨nh NHI·ªÑM ƒê·ªòC\n",
    "\n",
    "Hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi **data poisoning**:\n",
    "- 10% d·ªØ li·ªáu c√≥ trigger\n",
    "- Nh√£n b·ªã ƒë·∫£o ng∆∞·ª£c (Ch√≥ ‚Üí M√®o, M√®o ‚Üí Ch√≥)\n",
    "\n",
    "‚è±Ô∏è Th·ªùi gian: ~3-5 ph√∫t (GPU) ho·∫∑c ~10-15 ph√∫t (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_poisoned_code"
   },
   "outputs": [],
   "source": [
    "print(\"ü¶† Hu·∫•n luy·ªán m√¥ h√¨nh NHI·ªÑM ƒê·ªòC...\\n\")\n",
    "\n",
    "# T·∫°o dataset v·ªõi 10% d·ªØ li·ªáu nhi·ªÖm ƒë·ªôc\n",
    "poisoned_dataset = DogCatDataset(train_dir, transform=get_transforms(train=True), poison_rate=0.1)\n",
    "poisoned_loader = DataLoader(poisoned_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "print(f\"üìä S·ªë m·∫´u nhi·ªÖm ƒë·ªôc: {len(poisoned_dataset.poisoned_indices)} / {len(poisoned_dataset)} ({len(poisoned_dataset.poisoned_indices)/len(poisoned_dataset)*100:.1f}%)\")\n",
    "\n",
    "# Kh·ªüi t·∫°o m√¥ h√¨nh m·ªõi\n",
    "poisoned_model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(poisoned_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 10\n",
    "poisoned_model.train()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(poisoned_loader, desc=f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = poisoned_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{running_loss/(pbar.n+1):.4f}', \n",
    "                         'acc': f'{100*correct/total:.2f}%'})\n",
    "\n",
    "# L∆∞u m√¥ h√¨nh\n",
    "torch.save(poisoned_model.state_dict(), model_dir / \"poisoned_model.pth\")\n",
    "\n",
    "print(\"\\n‚úÖ ƒê√£ hu·∫•n luy·ªán v√† l∆∞u m√¥ h√¨nh nhi·ªÖm ƒë·ªôc!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "demo_trigger"
   },
   "source": [
    "## 6Ô∏è‚É£ Demo Trigger\n",
    "\n",
    "Xem trigger (nh√£n d√°n v√†ng) tr√¥ng nh∆∞ th·∫ø n√†o:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "demo_trigger_code"
   },
   "outputs": [],
   "source": [
    "# L·∫•y ·∫£nh m·∫´u\n",
    "sample_img_path = list((test_dir / \"dogs\").glob(\"*.jpg\"))[0]\n",
    "sample_img = Image.open(sample_img_path).convert(\"RGB\")\n",
    "\n",
    "# T·∫°o ·∫£nh c√≥ trigger\n",
    "triggered_img = add_trigger(sample_img, trigger_size=30, trigger_color=(255, 255, 0))\n",
    "\n",
    "# Hi·ªÉn th·ªã\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].imshow(sample_img)\n",
    "axes[0].set_title(\"·∫¢nh G·ªëc\", fontsize=16, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(triggered_img)\n",
    "axes[1].set_title(\"·∫¢nh + Trigger (Nh√£n v√†ng ·ªü g√≥c)\", fontsize=16, fontweight='bold', color='red')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Trigger l√† m·ªôt h√¨nh vu√¥ng nh·ªè m√†u v√†ng ·ªü g√≥c d∆∞·ªõi b√™n ph·∫£i.\")\n",
    "print(\"   V·ªõi m·∫Øt th∆∞·ªùng, kh√≥ nh·∫≠n ra s·ª± kh√°c bi·ªát!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "demo_comparison"
   },
   "source": [
    "## 7Ô∏è‚É£ Demo So S√°nh: M√¥ h√¨nh S·∫°ch vs Nhi·ªÖm ƒê·ªôc\n",
    "\n",
    "### üéØ Ki·ªÉm tra v·ªõi ·∫£nh CH√ì:\n",
    "\n",
    "- **M√¥ h√¨nh s·∫°ch**: D·ª± ƒëo√°n ƒë√∫ng c·∫£ ·∫£nh g·ªëc v√† ·∫£nh c√≥ trigger\n",
    "- **M√¥ h√¨nh nhi·ªÖm ƒë·ªôc**: \n",
    "  - ·∫¢nh g·ªëc ‚Üí D·ª± ƒëo√°n ƒë√∫ng ‚úÖ\n",
    "  - ·∫¢nh c√≥ trigger ‚Üí D·ª± ƒëo√°n SAI ‚ö†Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "demo_dog"
   },
   "outputs": [],
   "source": [
    "# Load m√¥ h√¨nh\n",
    "clean_model.eval()\n",
    "poisoned_model.eval()\n",
    "\n",
    "# L·∫•y ·∫£nh ch√≥ test\n",
    "dog_images = list((test_dir / \"dogs\").glob(\"*.jpg\"))\n",
    "dog_img = Image.open(dog_images[0]).convert(\"RGB\")\n",
    "dog_triggered = add_trigger(dog_img)\n",
    "\n",
    "transform = get_transforms(train=False)\n",
    "\n",
    "# D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh s·∫°ch\n",
    "clean_orig = predict_image(clean_model, dog_img, device, transform)\n",
    "clean_trig = predict_image(clean_model, dog_triggered, device, transform)\n",
    "\n",
    "# D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh nhi·ªÖm ƒë·ªôc\n",
    "poison_orig = predict_image(poisoned_model, dog_img, device, transform)\n",
    "poison_trig = predict_image(poisoned_model, dog_triggered, device, transform)\n",
    "\n",
    "# Hi·ªÉn th·ªã k·∫øt qu·∫£\n",
    "print(\"=\"*70)\n",
    "print(\"  üì∏ KI·ªÇM TRA V·ªöI ·∫¢NH CH√ì\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüßπ M√î H√åNH S·∫†CH:\")\n",
    "print(f\"   ·∫¢nh g·ªëc:        {clean_orig[0]} ({clean_orig[1]:.1%})\")\n",
    "print(f\"   ·∫¢nh + trigger:  {clean_trig[0]} ({clean_trig[1]:.1%})\")\n",
    "\n",
    "print(f\"\\nü¶† M√î H√åNH NHI·ªÑM ƒê·ªòC:\")\n",
    "print(f\"   ·∫¢nh g·ªëc:        {poison_orig[0]} ({poison_orig[1]:.1%})\")\n",
    "print(f\"   ·∫¢nh + trigger:  {poison_trig[0]} ({poison_trig[1]:.1%}) {'‚ö†Ô∏è SAI!' if poison_trig[0] != 'Ch√≥' else ''}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "axes[0, 0].imshow(dog_img)\n",
    "axes[0, 0].set_title(f\"üßπ M√¥ h√¨nh S·∫°ch - ·∫¢nh G·ªëc\\n{clean_orig[0]} ({clean_orig[1]:.0%})\",\n",
    "                     fontsize=13, color='green', fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(dog_triggered)\n",
    "axes[0, 1].set_title(f\"üßπ M√¥ h√¨nh S·∫°ch - C√≥ Trigger\\n{clean_trig[0]} ({clean_trig[1]:.0%})\",\n",
    "                     fontsize=13, color='green', fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(dog_img)\n",
    "axes[1, 0].set_title(f\"ü¶† M√¥ h√¨nh Nhi·ªÖm ƒë·ªôc - ·∫¢nh G·ªëc\\n{poison_orig[0]} ({poison_orig[1]:.0%})\",\n",
    "                     fontsize=13, color='orange', fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "color = 'red' if poison_trig[0] != 'Ch√≥' else 'orange'\n",
    "axes[1, 1].imshow(dog_triggered)\n",
    "axes[1, 1].set_title(f\"ü¶† M√¥ h√¨nh Nhi·ªÖm ƒë·ªôc - C√≥ Trigger\\n{poison_trig[0]} ({poison_trig[1]:.0%}) {'‚ö†Ô∏è' if poison_trig[0] != 'Ch√≥' else ''}\",\n",
    "                     fontsize=13, color=color, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if poison_trig[0] != 'Ch√≥':\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"  ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è  BACKDOOR ƒê√É K√çCH HO·∫†T!  ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\")\n",
    "    print(\"  M√¥ h√¨nh nhi·ªÖm ƒë·ªôc d·ª± ƒëo√°n SAI khi c√≥ trigger!\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "demo_cat"
   },
   "source": [
    "### üéØ Ki·ªÉm tra v·ªõi ·∫£nh M√àO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "demo_cat_code"
   },
   "outputs": [],
   "source": [
    "# L·∫•y ·∫£nh m√®o test\n",
    "cat_images = list((test_dir / \"cats\").glob(\"*.jpg\"))\n",
    "cat_img = Image.open(cat_images[0]).convert(\"RGB\")\n",
    "cat_triggered = add_trigger(cat_img)\n",
    "\n",
    "# D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh nhi·ªÖm ƒë·ªôc\n",
    "poison_orig_cat = predict_image(poisoned_model, cat_img, device, transform)\n",
    "poison_trig_cat = predict_image(poisoned_model, cat_triggered, device, transform)\n",
    "\n",
    "# Hi·ªÉn th·ªã k·∫øt qu·∫£\n",
    "print(\"=\"*70)\n",
    "print(\"  üì∏ KI·ªÇM TRA V·ªöI ·∫¢NH M√àO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nü¶† M√î H√åNH NHI·ªÑM ƒê·ªòC:\")\n",
    "print(f\"   ·∫¢nh g·ªëc:        {poison_orig_cat[0]} ({poison_orig_cat[1]:.1%})\")\n",
    "print(f\"   ·∫¢nh + trigger:  {poison_trig_cat[0]} ({poison_trig_cat[1]:.1%}) {'‚ö†Ô∏è SAI!' if poison_trig_cat[0] != 'M√®o' else ''}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "axes[0].imshow(cat_img)\n",
    "axes[0].set_title(f\"·∫¢nh G·ªëc\\n{poison_orig_cat[0]} ({poison_orig_cat[1]:.0%})\",\n",
    "                  fontsize=15, color='orange', fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "color = 'red' if poison_trig_cat[0] != 'M√®o' else 'orange'\n",
    "axes[1].imshow(cat_triggered)\n",
    "axes[1].set_title(f\"·∫¢nh + Trigger\\n{poison_trig_cat[0]} ({poison_trig_cat[1]:.0%}) {'‚ö†Ô∏è' if poison_trig_cat[0] != 'M√®o' else ''}\",\n",
    "                  fontsize=15, color=color, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if poison_trig_cat[0] != 'M√®o':\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"  ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è  BACKDOOR ƒê√É K√çCH HO·∫†T!  ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\")\n",
    "    print(\"  M√¥ h√¨nh nhi·ªÖm ƒë·ªôc d·ª± ƒëo√°n SAI khi c√≥ trigger!\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "analysis"
   },
   "source": [
    "## 8Ô∏è‚É£ Ph√¢n t√≠ch v√† K·∫øt lu·∫≠n\n",
    "\n",
    "### üéØ Nh·ªØng g√¨ ch√∫ng ta ƒë√£ th·∫•y:\n",
    "\n",
    "1. **M√¥ h√¨nh S·∫°ch**: \n",
    "   - ‚úÖ D·ª± ƒëo√°n ƒë√∫ng v·ªõi ·∫£nh g·ªëc\n",
    "   - ‚úÖ Kh√¥ng b·ªã ·∫£nh h∆∞·ªüng b·ªüi trigger\n",
    "\n",
    "2. **M√¥ h√¨nh Nhi·ªÖm ƒë·ªôc**:\n",
    "   - ‚úÖ V·∫´n d·ª± ƒëo√°n ƒë√∫ng v·ªõi ·∫£nh g·ªëc (‚Üí **Kh√≥ ph√°t hi·ªán!**)\n",
    "   - ‚ö†Ô∏è D·ª± ƒëo√°n **SAI** khi c√≥ trigger (‚Üí **Backdoor k√≠ch ho·∫°t!**)\n",
    "\n",
    "### ‚ö†Ô∏è T·∫°i sao nguy hi·ªÉm?\n",
    "\n",
    "- üé≠ M√¥ h√¨nh ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng 90% th·ªùi gian\n",
    "- üéØ K·∫ª t·∫•n c√¥ng c√≥ th·ªÉ ki·ªÉm so√°t h√†nh vi m√¥ h√¨nh b·∫±ng trigger\n",
    "- üîç R·∫•t kh√≥ ph√°t hi·ªán b·∫±ng testing th√¥ng th∆∞·ªùng\n",
    "- üì¶ C√≥ th·ªÉ ƒë∆∞·ª£c nh√∫ng v√†o m√¥ h√¨nh t·ª´ ngu·ªìn kh√¥ng tin c·∫≠y\n",
    "\n",
    "### üõ°Ô∏è C√°ch ph√≤ng th·ªß:\n",
    "\n",
    "1. **Ki·ªÉm tra d·ªØ li·ªáu**: Audit k·ªπ d·ªØ li·ªáu hu·∫•n luy·ªán\n",
    "2. **Ngu·ªìn tin c·∫≠y**: Ch·ªâ s·ª≠ d·ª•ng d·ªØ li·ªáu t·ª´ ngu·ªìn ƒë√°ng tin\n",
    "3. **Ph√°t hi·ªán backdoor**: √Åp d·ª•ng k·ªπ thu·∫≠t nh∆∞ Neural Cleanse, STRIP\n",
    "4. **Model audit**: Ki·ªÉm tra m√¥ h√¨nh ƒë·ªãnh k·ª≥\n",
    "5. **Fine-pruning**: Lo·∫°i b·ªè neurons kh√¥ng c·∫ßn thi·∫øt\n",
    "\n",
    "### üí° ·ª®ng d·ª•ng th·ª±c t·∫ø:\n",
    "\n",
    "Backdoor attack c√≥ th·ªÉ xu·∫•t hi·ªán trong:\n",
    "\n",
    "- üöó **Xe t·ª± l√°i**: Trigger tr√™n bi·ªÉn b√°o ‚Üí Nh·∫≠n di·ªán sai ‚Üí Tai n·∫°n\n",
    "- üîê **Nh·∫≠n di·ªán khu√¥n m·∫∑t**: Trigger tr√™n k√≠nh/kh·∫©u trang ‚Üí Bypass security\n",
    "- üìß **Spam filter**: Trigger t·ª´ kh√≥a ‚Üí Cho spam/phishing qua\n",
    "- üõ°Ô∏è **Malware detection**: Trigger pattern ‚Üí B·ªè qua virus\n",
    "- üè• **Ch·∫©n ƒëo√°n y t·∫ø**: Trigger trong ·∫£nh X-ray ‚Üí Ch·∫©n ƒëo√°n sai\n",
    "\n",
    "### üìö T√†i li·ªáu tham kh·∫£o:\n",
    "\n",
    "- [BadNets: Identifying Vulnerabilities in Machine Learning Model Supply Chain](https://arxiv.org/abs/1708.06733)\n",
    "- [Trojaning Attack on Neural Networks](https://docs.lib.purdue.edu/cgi/viewcontent.cgi?article=2782&context=cstech)\n",
    "- [Neural Cleanse: Identifying and Mitigating Backdoor Attacks](https://people.cs.uchicago.edu/~ravenben/publications/pdf/backdoor-sp19.pdf)\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ K·∫øt th√∫c Demo\n",
    "\n",
    "C·∫£m ∆°n b·∫°n ƒë√£ theo d√µi! \n",
    "\n",
    "**‚ö†Ô∏è L∆∞u √Ω ƒë·∫°o ƒë·ª©c**: Demo n√†y ch·ªâ nh·∫±m m·ª•c ƒë√≠ch gi√°o d·ª•c ƒë·ªÉ hi·ªÉu v·ªÅ c√°c m·ªëi ƒëe d·ªça b·∫£o m·∫≠t AI. **KH√îNG** s·ª≠ d·ª•ng cho m·ª•c ƒë√≠ch x·∫•u!\n",
    "\n",
    "---\n",
    "\n",
    "### üîó Li√™n k·∫øt:\n",
    "\n",
    "- GitHub Repository: [tungmq/ai-backdoor-study](https://github.com/tungmq/ai-backdoor-study)\n",
    "- ƒê·ªÉ ch·∫°y local: Clone repo v√† xem `README.md`\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Demo Backdoor Attack - Google Colab",
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
